#!/usr/bin/env python
import pandas as pd
import geopandas as gpd
#Need raster backend to handle large data
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import os
import sys
from itertools import islice
import multiprocessing as mp
import time
import psutil
from math import ceil
from osgeo import gdal
gdal.UseExceptions()

import argparse
parser = argparse.ArgumentParser(description="Analyze mesh and DEM properties")
parser.add_argument('meshDirectory', help='Directory containing mesh data, specifically the elements.shp, elements.wkt, mesh.1.ele, mesh.1.node, and mesh.1.z.\nBy default this directory will also be used for all output.')
parser.add_argument('-o','--output', help='Optional output directory.')
parser.add_argument('-n','--name', help='Name of the mesh, defaults to the input directory basename.')
parser.add_argument('-r','--readGeometry', help='Read preveiously created geoemtry attributes from the input directory.', action='store_true')
parser.add_argument('-p','--polygon', help='Dissolve the mesh triangles into a single outline polygon', action='store_true')
parser.add_argument('-g','--geometry', help='Calculate element geometry, including normalized unit vector and slopes.  Geometry data is saved as a pandas dataframe in <meshDirectory>/element_geometry.msg.', action='store_true')
parser.add_argument('-a','--area', help='Generate an area histogram of mesh elements.', action='store_true')
parser.add_argument('-t','--tin', help='Generate a cumulative distribution of raw TIN slopes.', action='store_true')
parser.add_argument('-d','--dem', help='Generate a cumulative distribtion of raw DEM slopes.', action='store_true')
parser.add_argument('-b','--both', help='Compare the DEM and TIN slope cumulative distributions.', action='store_true')
parser.add_argument('-i','--image', help='Raster Image to use for DEM analysis.  Required if --dem or --both is provided.')
args = parser.parse_args()

sys.path.append('/project/CI-WATER/nfrazie1/local/share/qgis/python/')
from qgis.core import *
from qgis.analysis import QgsGeometryAnalyzer

qgishome='/project/CI-WATER/nfrazie1/local'
app = QgsApplication([], True)
app.setPrefixPath(qgishome, True)
app.initQgis()

from parallelSort import numpyParallelSort

# input_directory_path
input_directory_path =  os.path.abspath(args.meshDirectory)

# This script will write its output to this directory
# the files it will write are:
#
# output_directory_path/histogram
output_directory_path = os.path.abspath(args.output) if args.output else input_directory_path
mesh_name = args.name if args.name else os.path.basename(input_directory_path)

raster_path = args.image #'/project/CI-WATER/data/tmp/sd8_mosaic_shpclip.tiff'
#Mesh geometry (WKT) file (can be generated by the generate wkt script)
WKTpath           = os.path.join(input_directory_path, 'elements.wkt')
mesh_vector_uri = 'file:///'+WKTpath+'?type=csv&delimiter=%s&crs=USER:100000&&wktField=Polygon&spatialIndex=no&subsetIndex=no&watchFile=no'
ELEfilepath = os.path.join(input_directory_path, 'mesh.1.ele')
NODEfilepath = os.path.join(input_directory_path, 'mesh.1.node')
Zfilepath = os.path.join(input_directory_path, 'mesh.1.z')

def mem_usage(GB=False):
    process = psutil.Process(os.getpid())
    mem = process.memory_info()[0]/float(2**20)
    if GB:
        mem = mem*0.00104858
    return mem


print "Analyzing mesh"

def dissolve_mesh():
    """
        Function for dissolving the peremiter of the mesh to generate an outline polygon.
    """
    #Suprisingly, geopandas (using shapely) can dissolve the mesh triangles (elements.shp)
    #relatively quickly (a little over an hour on the Upper Colorado River (~9,000,000 elements)
    #To increase speed, can union the geometry of mesh_catchments.shp, takes about 20 minutes,
    #and provides an outline polygon almost identical (difference is 0.359375 square meters!) 
    #df = gpd.read_file(os.path.join(input_directory_path, 'elements.shp'))
    df = gpd.read_file(os.path.join(input_directory_path, 'mesh_catchments.shp'))
    g = df.geometry
    g = gpd.GeoSeries([g.unary_union])
    g.to_file(os.path.join(output_directory_path, 'outline.shp'))
    return 
    
def calculate_elem_geom():
  """
      This function calculates the area, unit normal vector, and slope of each element.
  """
  elements = pd.read_csv(ELEfilepath, sep=' ', skipinitialspace=True, comment='#', skiprows=1, names=['ID', 'V1', 'V2', 'V3', 'CatchmentNumber'], index_col=0, engine='c').dropna()
  nodes = pd.read_csv(NODEfilepath, sep=' ', skipinitialspace=True, comment='#', skiprows=1, names=['ID', 'X', 'Y', 'Z'], index_col=0, engine='c').dropna()
  zs = pd.read_csv(Zfilepath, sep=' ', skipinitialspace=True, comment='#', skiprows=1, names=['ID', 'Z'], index_col=0, engine='c').dropna()

  print "Finding verticie coordinates"

  #We want the coordinates of each verticie, name them X1,Y1,Z1; X2,Y2,Z2; X3,Y3,Z3 respectively
  #First get X Y Coordinates of each elements V1 vertex, drop the "Z" that comes with these
  v1 = nodes.loc[elements['V1']].drop(['Z'], axis=1)
  #Now look up the Z value for each of these nodes
  z1 = zs.loc[v1.index]
  #Combine them together, reset the index, and rename the columns
  v1 = pd.concat([v1, z1], axis=1).reset_index().drop(['ID'], axis=1).rename(columns={'X':'X1','Y':'Y1','Z':'Z1'})

  #Repeat for v2 and v3
  v2 = nodes.loc[elements['V2']].drop(['Z'], axis=1)
  z2 = zs.loc[v2.index]
  v2 = pd.concat([v2, z2], axis=1).reset_index().drop(['ID'], axis=1).rename(columns={'X':'X2','Y':'Y2','Z':'Z2'})

  v3 = nodes.loc[elements['V3']].drop(['Z'], axis=1)
  z3 = zs.loc[v3.index]
  v3 = pd.concat([v3, z3], axis=1).reset_index().drop(['ID'], axis=1).rename(columns={'X':'X3','Y':'Y3','Z':'Z3'})


  elements = pd.concat([elements, v1, v2, v3], axis=1)
  print "Done compiling verticies"

  print "Calculating element area"
  elements['Area'] = abs( elements['X1']*(elements['Y2']-elements['Y3']) +\
                          elements['X2']*(elements['Y3']-elements['Y1']) +\
                          elements['X3']*(elements['Y1']-elements['Y2']))/2.0
  print "Done calculating area"

  print "Calculating element normal vectors"
  #elements = elements.apply(element_norm, axis=1)
  #Vectorize these calculations, makes it faster
  #Start by calculating vectors A and B from coordinates of the element
  elements['aX'] = elements['X2']-elements['X1']
  elements['aY'] = elements['Y2']-elements['Y1']
  elements['aZ'] = elements['Z2']-elements['Z1']
  elements['bX'] = elements['X3']-elements['X1']
  elements['bY'] = elements['Y3']-elements['Y1']
  elements['bZ'] = elements['Z3']-elements['Z1']
  #Now calculate the normal vector by taking the cross product of A and B
  elements['Nx'] = elements['aY']*elements['bZ'] - elements['aZ']*elements['bY']
  elements['Ny'] = elements['aZ']*elements['bX'] - elements['aX']*elements['bZ']
  elements['Nz'] = elements['aX']*elements['bY'] - elements['aY']*elements['bX']
  #calculate the magnitude of each vector
  elements['N_mag'] = pd.np.sqrt(sum([elements['Nx']**2, elements['Ny']**2, elements['Nz']**2]))
  #Find the coordinates of the normalized unit vector
  elements['N_ux'] = elements['Nx']/elements['N_mag']
  elements['N_uy'] = elements['Ny']/elements['N_mag']
  elements['N_uz'] = elements['Nz']/elements['N_mag']
  print "Done calculating element normal vectors"

  print "Calculating element slope"
  elements['Slope'] = pd.np.arccos(elements['N_uz'])
  print "Done calculating element slope"
  #elements['Slope'] = pd.np.degrees(elements['Slope'])
  elements.to_msgpack(os.path.join(output_directory_path, 'element_geometry.msg'))

  return elements

def slope_hist(elements):
  """
    Create a cumulative density plot of the slopes of TIN elements.
  """
  #hitsogram output file
  output_file = os.path.join(output_directory_path, 'tin_slope_histogram.pdf')
  
  s = elements['Slope'].sort_values()
  smin = s.iloc[0]
  smax = s.iloc[-1]
  cum_dist = pd.np.linspace(0.0, 1.0, len(s))
  slopes = pd.Series(cum_dist, index=s)
  print slopes
  fig = plt.figure()
  ax = slopes.plot(drawstyle='steps')
  ax.set_xlim(smin, smax)
  ax.set_xlabel("Mesh Slope")
  ax.set_title(mesh_name)
  fig.savefig(output_file)

def area_hist(elements):
  """
    Create a histogram (pdf) of the areas of TIN elements
  """
  #hitsogram output file  i
  name = os.path.split(input_directory_path)[-1]
  output_file = os.path.join(output_directory_path, 'area_'+name+'.pdf')
  areas = elements['Area']
  #Area is square meters, convert to ha
  areas = areas/10000
  #print areas
  fig = plt.figure()
  bin_width = 1
  bin_range = pd.np.arange(areas.min(), areas.max() + bin_width, bin_width) 
  #bin_range = pd.np.linspace(areas.min(), areas.max(), 10)
  #print bin_range
  ax = areas.plot(kind='hist', bins=bin_range, log=True)
  ax.set_xlim(areas.min(), areas.max())
  ax.set_xlabel("Area (ha)")
  ax.set_title(mesh_name)
  fig.savefig(output_file)
  print "Created ",output_file

from math import pi
def dem_hist():
    name = os.path.split(input_directory_path)[-1]
    output_file = os.path.join(output_directory_path, 'dem_slope_'+name+'.pdf')
    data = gdal.Open(raster_path)
    if data is None:
        sys.exit("Error opening raster")
    x = data.RasterXSize
    y = data.RasterYSize
    #Assume single band raster
    band = data.GetRasterBand(1)
    noData = band.GetNoDataValue()
    if not noData:
        noData = -1
    #really only care about the values at this point
    raster = band.ReadAsArray().flatten()
    raster = raster[ raster != noData ] 
    #df = pd.DataFrame(band.ReadAsArray()).replace(-1, pd.np.nan)
    print len(raster)
    print type(raster[0])
    numpyParallelSort(raster)
    print type(raster[0])
    #df = pd.Series(raster)
    #print "0 - pi/2  ", len(raster[raster < pi/2 ])
    #print "pi/2 - 3pi/2  ", len(raster[(raster > pi/2) & (raster < 3*pi/2)])
    #print "3pi/2 - 5pi/2  ", len(raster[(raster > 3*pi/2) & (raster < 5*pi/2)])
    #print "5pi/2 - 7pi/2  ", len(raster[(raster > 5*pi/2) & (raster < 7*pi/2)])
    #print "7pi/2 - 9pi/2  ", len(raster[(raster > 7*pi/2) & (raster < 9*pi/2)])
    #print "9pi/2 - 11pi/2  ", len(raster[(raster > 9*pi/2) & (raster < 11*pi/2)])
    cum_dist = pd.np.linspace(0.0,1.0,len(raster))
    #slopes = pd.Series(cum_dist, index=df)
    fig = plt.figure()
    
    plt.plot(raster, cum_dist, drawstyle='step', label="DEM Slope")
    ax = plt.gca()
    ax.set_xlim(raster[0], 1.3)
    ax.set_xlabel("DEM Slope")
    ax.set_title(mesh_name)
    fig.savefig(output_file)
    print "Created ",output_file

def slope_compare(elements):
    #Init the plot 
    fig = plt.figure()
    #Set the output file
    name = os.path.split(input_directory_path)[-1]
    output_file = os.path.join(output_directory_path, 'slope_comparison_'+name+'.pdf')
    #Read raster
    data = gdal.Open(raster_path)
    if data is None:
        sys.exit("Error opening raster")
    x = data.RasterXSize
    y = data.RasterYSize
    ##Assume single band raster
    band = data.GetRasterBand(1)
    noData = band.GetNoDataValue()
    if not noData:
        noData = -1
    #really only care about the values at this point
    raster = band.ReadAsArray().flatten()
    del band
    raster = raster[ raster != noData ] 
    #To speed up large mesh processing, sort in parallel
    numpyParallelSort(raster)
    rmin = raster[0]
    rmax = raster[-1]
    raster_cum_dist = pd.np.linspace(0.0,1.0,len(raster))
    #Plot this distribution

    plt.plot(raster, raster_cum_dist, drawstyle='step', label="% of DEM with Slope S")
    #Clean up the memory used by the raster
    del raster
    del raster_cum_dist

    #Now plot pure slope distribution
    tin = elements['Slope'].values
    numpyParallelSort(tin)
    tmin = tin[0]
    tmax = tin[-1]
    tin_cum_dist = pd.np.linspace(0.0,1.0,len(tin))
    plt.plot(tin, tin_cum_dist, drawstyle='step', label='% of TIN elements with Slope S')
    #clean up memory
    del tin
    del tin_cum_dist

    p_area = 9.31978**2
    #Each TIN elements accounts for UAC (Unit Area Count) pixels worth of area
    elements['UAC'] = elements['Area']/p_area
    tot  = elements['UAC'].sum()
    
    ms = elements[['UAC','Slope']].sort_values('Slope')
    ms['UAC'] = ms['UAC']/tot
    ms.set_index('Slope', inplace=True)
    ms['CUM'] = ms.cumsum()
    """
    #Compared this to ^^^ method, and they are the same...onle ^^^ is much faster ;)
    elements['CUM'] = elements.apply(lambda x : (elements['UAC'][elements['Slope'] <= x['Slope']].sum())/tot, axis=1)
    #print elements
    cs = elements[['Slope','UAC','CUM']].set_index('Slope').sort_values('CUM')
    print cs
    print ms
    print cs[ cs['CUM'] != ms['CUM'] ]
    diff = cs['CUM'] - ms['CUM']
    print diff.max()
    """ 
    #Min should always be 0.  Due to the raster sometimes have excessively large slopes
    #for a small number of elements, set the max to be the max of the slopes found for the elements
    smin = min(tmin, rmin)
    smax = tmax if rmax - tmax > 1.5 else max(tmax, rmax)
    ax = ms['CUM'].plot(drawstyle='steps', label='% of DEM Area covered\nby TIN elements with Slope S')
    ax.legend(loc='lower right')
    ax.set_xlim(smin, smax)
    ax.set_ylim(0,1)
    ax.set_xlabel("Slope")
    ax.set_title(mesh_name)
    fig.savefig(output_file)
    print "Created ",output_file

if __name__ == "__main__":
  
  if (args.dem or args.both) and not args.image:
    parser.error("--image <path> is required to use --dem or --both.")

  if not args.readGeometry or args.geometry:
    print "Calculation element geometry"
    elements = calculate_elem_geom()
  else:
    print "Reading element_geometry.msg"
    elements = pd.read_msgpack((os.path.join(output_directory_path, 'element_geometry.msg')))
  
  if args.polygon:
    print "Dissolving mesh"
    dissolve_mesh()
  if args.area:
    print "Creating TIN area histogram"
    area_hist(elements)
  if args.tin:
    print "Creating TIN slope histogram"
    slope_hist(elements)
  if args.dem:
    print "Creating DEM slope histogram"
    dem_hist()
  if args.both:
    print "Creating DEM/TIN comparison histogram"
    slope_compare(elements)

#app.exitQgis()
